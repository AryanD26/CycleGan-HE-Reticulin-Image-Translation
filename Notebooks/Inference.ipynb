{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83745f-d9ac-4203-a418-bab99cace2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 1: Evaluation Setup and Configuration\n",
    "# ==============================================================================\n",
    "# This cell imports all necessary libraries and defines the configuration for\n",
    "# evaluating a trained CycleGAN model. It sets which model checkpoint to load\n",
    "# and where to find the necessary data and save the outputs.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Core Libraries ---\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Deep Learning & Data Processing Libraries ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import tifffile\n",
    "from torch_fidelity import calculate_metrics\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. EVALUATION CONFIGURATION\n",
    "# ==============================================================================\n",
    "# All user-configurable parameters are grouped here.\n",
    "\n",
    "# --- Model Selection ---\n",
    "# Set the epoch number of the trained model you want to evaluate.\n",
    "EPOCH_TO_EVALUATE = 50\n",
    "\n",
    "# --- Training Run Parameters ---\n",
    "# These parameters MUST exactly match the parameters of the training run you\n",
    "# are evaluating to ensure the correct checkpoint paths are constructed.\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 512\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# --- Evaluation Output Settings ---\n",
    "# Number of example image pairs to generate for the visual gallery.\n",
    "NUM_GALLERY_IMAGES = 10\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. SYSTEM & PATH SETUP (AUTOMATED)\n",
    "# ==============================================================================\n",
    "# This section automatically sets up devices and constructs all necessary paths\n",
    "# based on the configuration above.\n",
    "\n",
    "# --- Device Configuration ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Dynamic Path Construction ---\n",
    "# This ensures that all paths are consistent with the training run being evaluated.\n",
    "NOTEBOOK_CWD = os.getcwd()\n",
    "run_id_string = f\"cyclegan_bs{BATCH_SIZE}_img{IMG_SIZE}\" # Re-create the same run ID as training\n",
    "\n",
    "# Source paths for test data\n",
    "H_AND_E_BASE_DIR = \"H&E_split_dataset\"\n",
    "RETICULIN_BASE_DIR = \"Retic_split_dataset\"\n",
    "PATH_TEST_H_FOLDER  = os.path.join(NOTEBOOK_CWD, H_AND_E_BASE_DIR, \"test\")\n",
    "PATH_TEST_R_FOLDER  = os.path.join(NOTEBOOK_CWD, RETICULIN_BASE_DIR, \"test\")\n",
    "\n",
    "# Source path for model checkpoints\n",
    "CHECKPOINT_DIR = os.path.join(NOTEBOOK_CWD, \"checkpoints\", run_id_string)\n",
    "\n",
    "# Destination paths for evaluation outputs\n",
    "EVAL_OUTPUT_DIR = os.path.join(NOTEBOOK_CWD, \"evaluation_results\", run_id_string, f\"epoch_{EPOCH_TO_EVALUATE}\")\n",
    "os.makedirs(EVAL_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. INITIALIZATION & PRE-RUN CHECKS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"--- Starting Final Evaluation ---\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Evaluating Run ID: '{run_id_string}'\")\n",
    "print(f\"Loading Checkpoint from Epoch: {EPOCH_TO_EVALUATE}\")\n",
    "print(f\"Evaluation outputs will be saved to: {EVAL_OUTPUT_DIR}\")\n",
    "\n",
    "# --- Verify that the necessary checkpoint and data folders exist ---\n",
    "if not os.path.isdir(CHECKPOINT_DIR):\n",
    "    raise FileNotFoundError(f\"CRITICAL: Checkpoint directory not found at {CHECKPOINT_DIR}. Please ensure the run ID and paths are correct.\")\n",
    "\n",
    "if not os.path.isdir(PATH_TEST_H_FOLDER) or not os.path.isdir(PATH_TEST_R_FOLDER):\n",
    "    raise FileNotFoundError(f\"CRITICAL: One or more test data folders not found. Please check paths.\")\n",
    "\n",
    "print(\"\\n--- Cell 1 Setup Complete. Ready to load models and data. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fe184-7c9f-4a4c-825c-4e3d7c66e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: Load Trained Models and Test Data\n",
    "# ==============================================================================\n",
    "# This cell loads the trained generator models from the specified checkpoint\n",
    "# epoch and prepares the test dataset for inference and evaluation.\n",
    "# It assumes models and dataset classes are defined in separate .py files.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Import Custom Modules ---\n",
    "# Instead of copy-pasting class definitions, we import them.\n",
    "# This makes the code cleaner and ensures you're always using the same\n",
    "# model architecture as you did during training.\n",
    "# (This assumes you have created src/models.py and src/dataset.py)\n",
    "from src.models import Generator\n",
    "from src.dataset import PairedImageDataset\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. MODEL LOADING\n",
    "# ==============================================================================\n",
    "\n",
    "def load_generator_checkpoint(model, checkpoint_path):\n",
    "    \"\"\"\n",
    "    Loads a generator's weights from a saved checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): An instantiated generator model.\n",
    "        checkpoint_path (str): The full path to the .pth.tar checkpoint file.\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module or None: The model with loaded weights, or None on failure.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"!!! ERROR: Checkpoint file not found at '{checkpoint_path}'.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Loading checkpoint: {os.path.basename(checkpoint_path)}\")\n",
    "    try:\n",
    "        # Load the checkpoint dictionary onto the correct device (CPU or GPU)\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "        \n",
    "        # Load the weights into the model\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        \n",
    "        # Set the model to evaluation mode (disables dropout, etc.)\n",
    "        model.eval()\n",
    "        \n",
    "        print(\"... Success!\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERROR: Failed to load checkpoint. Reason: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Instantiate and Load the Generators ---\n",
    "# We only need the generators for evaluation, not the discriminators.\n",
    "\n",
    "# gen_H translates H&E -> Reticulin\n",
    "# gen_R translates Reticulin -> H&E\n",
    "gen_H = Generator(img_channels=IMG_CHANNELS, num_residuals=9).to(DEVICE)\n",
    "gen_R = Generator(img_channels=IMG_CHANNELS, num_residuals=9).to(DEVICE)\n",
    "\n",
    "# Construct the full paths to the checkpoint files to load\n",
    "checkpoint_path_H = os.path.join(CHECKPOINT_DIR, f\"genh_{run_id_string}_epoch{EPOCH_TO_EVALUATE}.pth.tar\")\n",
    "checkpoint_path_R = os.path.join(CHECKPOINT_DIR, f\"genr_{run_id_string}_epoch{EPOCH_TO_EVALUATE}.pth.tar\")\n",
    "\n",
    "# Load the weights\n",
    "gen_H = load_generator_checkpoint(gen_H, checkpoint_path_H)\n",
    "gen_R = load_generator_checkpoint(gen_R, checkpoint_path_R)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TEST DATASET PREPARATION\n",
    "# ==============================================================================\n",
    "# We use the same PairedImageDataset class from training to load the test data.\n",
    "# We do not need to specify steps_per_epoch, so it will use the full test set.\n",
    "\n",
    "if gen_H is not None and gen_R is not None:\n",
    "    # We only need to create the dataset if the models loaded successfully.\n",
    "    vis_dataset = PairedImageDataset(\n",
    "        root_H_folder=PATH_TEST_H_FOLDER,\n",
    "        root_R_folder=PATH_TEST_R_FOLDER,\n",
    "        domain_name=\"Evaluation\"\n",
    "    )\n",
    "    \n",
    "    # We create a DataLoader for efficient iteration during FID calculation.\n",
    "    # The batch size can be larger here to speed up image generation.\n",
    "    vis_dataloader = DataLoader(\n",
    "        vis_dataset,\n",
    "        batch_size=32, # Larger batch size for faster inference\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    print(f\"\\nTest dataset loaded with {len(vis_dataset)} images.\")\n",
    "    print(\"--- Cell 2 Model and Data Loading Complete ---\")\n",
    "else:\n",
    "    print(\"\\n!!! Halting due to model loading failure. Cannot proceed with evaluation. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c9ba7-3f04-4606-9dcc-e914b6ec336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3: Generate Visual Outputs (Gallery and FID Fakes)\n",
    "# ==============================================================================\n",
    "# This cell performs two tasks:\n",
    "# 1. Creates a visual gallery of sample translations.\n",
    "# 2. Generates a full set of fake images (as .tif) needed for FID calculation.\n",
    "# ==============================================================================\n",
    "\n",
    "def denormalize(t):\n",
    "    \"\"\"Converts a tensor from the [-1, 1] range back to a [0, 1] numpy array.\"\"\"\n",
    "    # Move tensor to CPU, convert to NumPy, and reorder to (H, W, C) for saving\n",
    "    return torch.clamp((t.cpu() + 1.0) / 2.0, 0.0, 1.0).permute(1, 2, 0).numpy()\n",
    "\n",
    "def generate_outputs(gen_H, gen_R, dataloader, num_gallery_images, fid_fake_dir_H, fid_fake_dir_R, gallery_dir):\n",
    "    \"\"\"\n",
    "    Generates all necessary visual outputs: a sample gallery and full sets of\n",
    "    fake images in TIFF format for FID calculation.\n",
    "    \"\"\"\n",
    "    if not dataloader:\n",
    "        print(\"!!! Dataloader not available, skipping output generation.\")\n",
    "        return\n",
    "\n",
    "    gen_H.eval()\n",
    "    gen_R.eval()\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(gallery_dir, exist_ok=True)\n",
    "    os.makedirs(fid_fake_dir_H, exist_ok=True)\n",
    "    os.makedirs(fid_fake_dir_R, exist_ok=True)\n",
    "    \n",
    "    # Use a larger batch size for efficient inference\n",
    "    eval_dataloader = DataLoader(dataloader.dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(\"\\n--- Generating all visual outputs ---\")\n",
    "    with torch.no_grad():\n",
    "        for i, (real_H_raw, real_R_raw) in enumerate(tqdm(eval_dataloader, desc=\"Generating Images\")):\n",
    "            real_H = transforms.Resize((IMG_SIZE, IMG_SIZE), antialias=True)(real_H_raw.to(DEVICE))\n",
    "            real_R = transforms.Resize((IMG_SIZE, IMG_SIZE), antialias=True)(real_R_raw.to(DEVICE))\n",
    "            \n",
    "            # --- Generate Fake Images ---\n",
    "            fake_R_batch = gen_H(real_H)  # H&E -> Fake Reticulin\n",
    "            fake_H_batch = gen_R(real_R)  # Reticulin -> Fake H&E\n",
    "\n",
    "            # --- Save Full Set for FID Calculation (as .tif) ---\n",
    "            for j in range(real_H.size(0)):\n",
    "                # Save fake Reticulin image (from real H&E)\n",
    "                fake_R_np = denormalize(fake_R_batch[j])\n",
    "                tifffile.imsave(os.path.join(fid_fake_dir_R, f\"fake_R_{i * 32 + j:05d}.tif\"), (fake_R_np * 255).astype(np.uint8))\n",
    "                \n",
    "                # Save fake H&E image (from real Reticulin)\n",
    "                fake_H_np = denormalize(fake_H_batch[j])\n",
    "                tifffile.imsave(os.path.join(fid_fake_dir_H, f\"fake_H_{i * 32 + j:05d}.tif\"), (fake_H_np * 255).astype(np.uint8))\n",
    "\n",
    "            # --- Save a few samples for the Visual Gallery (as .png) ---\n",
    "            if i < num_gallery_images:\n",
    "                gallery_row = torch.cat([\n",
    "                    denormalize(real_H[0].cpu().permute(1, 2, 0)),\n",
    "                    denormalize(fake_R_batch[0].cpu().permute(1, 2, 0)),\n",
    "                    denormalize(real_R[0].cpu().permute(1, 2, 0)),\n",
    "                    denormalize(fake_H_batch[0].cpu().permute(1, 2, 0))\n",
    "                ], dim=1) # Concatenate horizontally (dim=1 for H, W, C)\n",
    "                \n",
    "                plt.imsave(os.path.join(gallery_dir, f\"gallery_row_{i+1:02d}.png\"), gallery_row)\n",
    "\n",
    "    print(f\"Visual gallery saved in: {gallery_dir}\")\n",
    "    print(f\"Fake TIFFs for FID saved in: {fid_fake_dir_H} and {fid_fake_dir_R}\")\n",
    "\n",
    "# --- Define Paths and Execute ---\n",
    "GALLERY_OUTPUT_DIR = os.path.join(EVAL_OUTPUT_DIR, \"visual_gallery\")\n",
    "FID_FAKE_H_DIR = os.path.join(EVAL_OUTPUT_DIR, \"fid_fakes_H_from_R_tif\") # Fake H&E\n",
    "FID_FAKE_R_DIR = os.path.join(EVAL_OUTPUT_DIR, \"fid_fakes_R_from_H_tif\") # Fake Reticulin\n",
    "\n",
    "if 'gen_H' in locals() and 'gen_R' in locals() and gen_H is not None and gen_R is not None:\n",
    "    generate_outputs(\n",
    "        gen_H=gen_H,\n",
    "        gen_R=gen_R,\n",
    "        dataloader=vis_dataloader,\n",
    "        num_gallery_images=NUM_GALLERY_IMAGES,\n",
    "        gallery_dir=GALLERY_OUTPUT_DIR,\n",
    "        fid_fake_dir_H=FID_FAKE_H_DIR,\n",
    "        fid_fake_dir_R=FID_FAKE_R_DIR\n",
    "    )\n",
    "else:\n",
    "    print(\"!!! Models not loaded correctly, skipping output generation.\")\n",
    "\n",
    "print(\"\\n--- Cell 3 Image Generation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa9a05-efcb-4b2d-91c5-a2c33bfe4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Cell 4: Calculate Final Metrics and Generate Report\n",
    "# ==============================================================================\n",
    "# This cell uses the pre-generated fake TIFF images and the training log to\n",
    "# calculate the final FID scores and plot the complete loss curves.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- FID Calculation Function ---\n",
    "def calculate_fid_from_tif_folders(real_tif_folder, fake_tif_folder, domain_label):\n",
    "    \"\"\"Calculates FID between a folder of real and a folder of fake TIFF images.\"\"\"\n",
    "    print(f\"\\n--- Calculating FID for {domain_label} ---\")\n",
    "    try:\n",
    "        # Verify that both directories exist and contain .tif files\n",
    "        if not os.path.isdir(real_tif_folder) or not glob.glob(os.path.join(real_tif_folder, \"*.tif\")):\n",
    "            raise FileNotFoundError(f\"Real TIF images not found in: {real_tif_folder}\")\n",
    "        if not os.path.isdir(fake_tif_folder) or not glob.glob(os.path.join(fake_tif_folder, \"*.tif\")):\n",
    "            raise FileNotFoundError(f\"Fake TIF images not found in: {fake_tif_folder}\")\n",
    "\n",
    "        print(f\"Comparing real TIFs in '{os.path.basename(real_tif_folder)}' vs fake TIFs in '{os.path.basename(fake_tif_folder)}'\")\n",
    "        \n",
    "        # Tell torch-fidelity to look for .tif files in BOTH input directories\n",
    "        metrics = calculate_metrics(\n",
    "            input1=real_tif_folder,\n",
    "            input2=fake_tif_folder,\n",
    "            cuda=(DEVICE==\"cuda\"),\n",
    "            isc=False,\n",
    "            fid=True,\n",
    "            input1_exts=['tif'], # Specify for input 1\n",
    "            input2_exts=['tif']  # Specify for input 2\n",
    "        )\n",
    "        fid_score = metrics['frechet_inception_distance']\n",
    "        \n",
    "        print(f\"==========================================\")\n",
    "        print(f\"  FID Score for {domain_label}: {fid_score:.4f}\")\n",
    "        print(f\"==========================================\")\n",
    "        return fid_score\n",
    "    except Exception as e:\n",
    "        print(f\"!!! FID calculation failed for {domain_label}: {e}\")\n",
    "        return float('nan')\n",
    "\n",
    "# --- Log Parsing and Plotting Functions (Unchanged from previous correct version) ---\n",
    "# ... (Copy the robust parse_log_for_metrics and plot_final_metrics functions here) ...\n",
    "def parse_log_for_metrics(log_filepath):\n",
    "    history_keys = [\"gen_G_loss\", \"disc_H_loss\", \"disc_R_loss\", \"cycle_H_loss\", \"cycle_R_loss\", \"identity_H_loss\", \"identity_R_loss\"]\n",
    "    metrics_history = {key: [] for key in history_keys}\n",
    "    try:\n",
    "        with open(log_filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                if \"Summary. Time:\" in line and \"Avgs:\" in line:\n",
    "                    try:\n",
    "                        avg_part = line.split(\"Avgs:[\")[1].split(\"]\")[0]\n",
    "                        pairs = avg_part.split()\n",
    "                        epoch_data = {key.split(':')[0] + \"_loss\": float(key.split(':')[1]) for key in pairs}\n",
    "                        for key in history_keys:\n",
    "                            metrics_history[key].append(epoch_data.get(key, np.nan))\n",
    "                    except (IndexError, ValueError): pass\n",
    "    except FileNotFoundError: print(f\"!!! Log file not found at {log_filepath}\")\n",
    "    return metrics_history\n",
    "def plot_final_metrics(metrics_history, final_epoch, save_dir):\n",
    "    num_logged_epochs = max(len(v) for v in metrics_history.values() if v)\n",
    "    if num_logged_epochs == 0: return\n",
    "    epochs = list(range(1, num_logged_epochs + 1))\n",
    "    plot_groups = [{'title': 'Generator Adversarial Loss', 'keys': ['gen_G_loss']}, {'title': 'Discriminator Loss', 'keys': ['disc_H_loss', 'disc_R_loss']}, {'title': 'Cycle Consistency Loss', 'keys': ['cycle_H_loss', 'cycle_R_loss']}, {'title': 'Identity Loss', 'keys': ['identity_H_loss', 'identity_R_loss']}, {'title': 'Fréchet Inception Distance (FID)', 'keys': ['fid_A_score', 'fid_B_score']},]\n",
    "    fig, axes = plt.subplots(len(plot_groups), 1, figsize=(14, 7 * len(plot_groups)), sharex=True)\n",
    "    if len(plot_groups) == 1: axes = [axes]\n",
    "    for i, group in enumerate(plot_groups):\n",
    "        ax = axes[i]\n",
    "        for key in group['keys']:\n",
    "            if key in metrics_history and any(not np.isnan(v) for v in metrics_history.get(key, [])):\n",
    "                series_data = metrics_history[key]\n",
    "                padded_series = series_data + [np.nan] * (num_logged_epochs - len(series_data))\n",
    "                ax.plot(epochs, padded_series, marker='o', linestyle='-', label=key)\n",
    "        if num_logged_epochs <= 20: ax.set_xticks(epochs)\n",
    "        else: ax.set_xticks([e for e in epochs if e % 5 == 0 or e == 1])\n",
    "        ax.set_title(group['title'], fontsize=14); ax.set_ylabel(\"Loss / Score\"); ax.legend(); ax.grid(True)\n",
    "    axes[-1].set_xlabel(\"Epochs\"); fig.suptitle(f'Final Training Metrics up to Epoch {final_epoch}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97]);\n",
    "    save_path = os.path.join(save_dir, f'FINAL_metrics_graph_epoch_{final_epoch:04d}.png')\n",
    "    plt.savefig(save_path); plt.close(fig); print(f\"Saved final metrics graph to {save_path}\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "# Define paths to the TIFF image folders\n",
    "FID_FAKE_H_DIR = os.path.join(EVAL_OUTPUT_DIR, \"fid_fakes_H_from_R_tif\") # Fake H&E\n",
    "FID_FAKE_R_DIR = os.path.join(EVAL_OUTPUT_DIR, \"fid_fakes_R_from_H_tif\") # Fake Reticulin\n",
    "\n",
    "# Calculate FID scores\n",
    "fid_H_score = calculate_fid_from_tif_folders(PATH_TEST_H_FOLDER, FID_FAKE_H_DIR, \"Generated H&E\")\n",
    "fid_R_score = calculate_fid_from_tif_folders(PATH_TEST_R_FOLDER, FID_FAKE_R_DIR, \"Generated Reticulin\")\n",
    "\n",
    "# Find, parse, and plot\n",
    "log_files = sorted(glob.glob(os.path.join(NOTEBOOK_CWD, \"logs\", f\"train_log_{run_id_string}_*.log\")))\n",
    "if log_files:\n",
    "    latest_log_file = log_files[-1]\n",
    "    final_metrics_history = parse_log_for_metrics(latest_log_file)\n",
    "    num_epochs = len(final_metrics_history['gen_G_loss'])\n",
    "    final_metrics_history['fid_A_score'] = [np.nan] * num_epochs\n",
    "    final_metrics_history['fid_B_score'] = [np.nan] * num_epochs\n",
    "    if not np.isnan(fid_H_score) and EPOCH_EVALUATED <= num_epochs: final_metrics_history['fid_A_score'][EPOCH_EVALUATED-1] = fid_H_score\n",
    "    if not np.isnan(fid_R_score) and EPOCH_EVALUATED <= num_epochs: final_metrics_history['fid_B_score'][EPOCH_EVALUATED-1] = fid_R_score\n",
    "    plot_final_metrics(final_metrics_history, num_epochs, EVAL_OUTPUT_DIR)\n",
    "else:\n",
    "    print(\"!!! Log file not found. Cannot plot metrics.\")\n",
    "\n",
    "print(\"\\n--- Evaluation Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
